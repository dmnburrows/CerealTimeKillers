{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CerealTimeKillersNet: Deep neural network for emotional states predictions from EEG data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.6 (default, Jan  8 2020, 13:42:34) \\n[Clang 4.0.1 (tags/RELEASE_401/final)]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic packages\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Math packages\n",
    "import math\n",
    "from scipy.signal import spectrogram\n",
    "\n",
    "# Plot packages\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# PyTorch packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, SubsetRandomSampler, random_split\n",
    "\n",
    "# ML Packages\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "#Import your modules\n",
    "#---------------------------------------\n",
    "import admin_functions as adfn\n",
    "\n",
    "# Packages & self-implemented functions\n",
    "from CTK_net import *\n",
    "\n",
    "# Define paths\n",
    "#----------------------------------------------------------------------\n",
    "Fcode = '/Users/dominicburrows/Dropbox/PhD/Analysis/my_scripts/GitHub/'\n",
    "Fdata = '/Users/dominicburrows/Dropbox/PhD/analysis/Project/'\n",
    "Fdoc = '/Users/dominicburrows/Documents/'\n",
    "F10t = '/Volumes/Dominic 10tb/Data2process/Project/' \n",
    "F10t2 = '/Volumes/Dominic 10tb2/Data2process/Project/'\n",
    "Ftm = '/Volumes/Dominic Time Machine/'\n",
    "Ffig = '/Users/dominicburrows/Dropbox/PhD/figures/'\n",
    "\n",
    "%load_ext autoreload\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTKNet_RNN(nn.Module):\n",
    "    def __init__(self, input_shape, out_size):\n",
    "\n",
    "        super(CTKNet_RNN, self).__init__()\n",
    "        \n",
    "        # Model hyperparametres (layer by layer)\n",
    "        rnn_layer = [1]\n",
    "        rnn_unit = [128]\n",
    "        rnn_drop = [0]\n",
    "        fc_unit = [64]\n",
    "        drop_out = [0.5]\n",
    "        \n",
    "        self.rnn_layer = rnn_layer\n",
    "        self.rnn_unit = rnn_unit\n",
    "        \n",
    "        # Hidden layers\n",
    "        img_size = np.array(input_shape[2:])\n",
    "        \n",
    "        fc_input_size = np.int(np.prod(img_size) * input_shape[1])\n",
    "        \n",
    "        self.rnn1 = nn.LSTM(input_size = fc_input_size, hidden_size = rnn_unit[0], num_layers = rnn_layer[0], dropout = rnn_drop[0], batch_first = True)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features = rnn_unit[0] * rnn_layer[0], out_features = fc_unit[0])\n",
    "        self.drop1 = nn.Dropout(drop_out[0])\n",
    "        \n",
    "        self.fc2 = nn.Linear(in_features = fc_unit[0], out_features = out_size[0])\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        shape = x.shape\n",
    "        x = x.view(shape[0] * shape[1], shape[2], shape[3], shape[4])\n",
    "        \n",
    "        hidden = (torch.randn(self.rnn_layer[0], shape[0], self.rnn_unit[0]), \n",
    "                  torch.randn(self.rnn_layer[0], shape[0], self.rnn_unit[0]))   # for LSTM\n",
    "        # hidden = torch.randn(self.rnn_layer[0], shape[0], self.rnn_unit[0])   # for simple RNN and GRU\n",
    "        \n",
    "        x = torch.flatten(x, 1)        \n",
    "        x = x.view(shape[0], shape[1], -1)\n",
    "        _, x = self.rnn1(x, hidden) # use final hidden state for non-series label prediction!\n",
    "        x = x[0].permute(1, 0, 2) # for LSTM\n",
    "        # x = x.permute(1, 0, 2) # for simple RNN and GRU\n",
    "        x = F.relu(x)\n",
    "        x = x.contiguous().view(x.shape[0], -1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTKNet_CRNN_1(nn.Module):\n",
    "    def __init__(self, input_shape, out_size):\n",
    "\n",
    "        super(CTKNet_CRNN_1, self).__init__()\n",
    "        \n",
    "        # Model hyperparametres (layer by layer)\n",
    "        conv_channel = [5, 5]\n",
    "        conv_kernel = [(3, 3), (3, 3)]\n",
    "        pool_kernel = [(1, 1), (1, 1)]\n",
    "        rnn_layer = [1]\n",
    "        rnn_unit = [64]\n",
    "        rnn_drop = [0]\n",
    "        fc_unit = []\n",
    "        drop_out = []\n",
    "        \n",
    "        self.rnn_layer = rnn_layer\n",
    "        self.rnn_unit = rnn_unit\n",
    "        \n",
    "        # Hidden layers\n",
    "        img_size = np.array(input_shape[2:])\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels = input_shape[1], out_channels = conv_channel[0], kernel_size = conv_kernel[0])\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size = pool_kernel[0])\n",
    "        img_size = np.floor((img_size - np.array(conv_kernel[0]) + 1.0) / np.array(pool_kernel[0]))\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = conv_channel[0], out_channels = conv_channel[1], kernel_size = conv_kernel[1])\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size = pool_kernel[1])\n",
    "        img_size = np.floor((img_size - np.array(conv_kernel[1]) + 1.0) / np.array(pool_kernel[1]))\n",
    "        \n",
    "        fc_input_size = np.int(np.prod(img_size) * conv_channel[1])\n",
    "        \n",
    "        self.rnn1 = nn.LSTM(input_size = fc_input_size, hidden_size = rnn_unit[0], num_layers = rnn_layer[0], dropout = rnn_drop[0], batch_first = True)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features = rnn_unit[0] * rnn_layer[0], out_features = out_size[0])\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        shape = x.shape\n",
    "        x = x.view(shape[0] * shape[1], shape[2], shape[3], shape[4])\n",
    "        \n",
    "        hidden = (torch.randn(self.rnn_layer[0], shape[0], self.rnn_unit[0], generator = None), \n",
    "                  torch.randn(self.rnn_layer[0], shape[0], self.rnn_unit[0], generator = None))   # for LSTM\n",
    "        # hidden = torch.randn(self.rnn_layer[0], shape[0], self.rnn_unit[0], generator = None)   # for simple RNN and GRU\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)        \n",
    "        x = x.view(shape[0], shape[1], -1)\n",
    "        _, x = self.rnn1(x, hidden) # use final hidden state for non-series label prediction!\n",
    "        x = x[0].permute(1, 0, 2) # for LSTM\n",
    "        # x = x.permute(1, 0, 2) # for simple RNN and GRU\n",
    "        x = F.relu(x)\n",
    "        x = x.contiguous().view(x.shape[0], -1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTKNet_CRNN_2(nn.Module):\n",
    "    def __init__(self, input_shape, out_size):\n",
    "\n",
    "        super(CTKNet_CRNN_2, self).__init__()\n",
    "        \n",
    "        # Model hyperparametres (layer by layer)\n",
    "        conv_channel = [20, 10, 5]\n",
    "        conv_kernel = [3, 5, 10]\n",
    "        pool_kernel = [1, 2, 2]\n",
    "        rnn_layer = [1]\n",
    "        rnn_unit = [128]\n",
    "        rnn_drop = [0]\n",
    "        fc_unit = [64]\n",
    "        drop_out = [0.5]\n",
    "        \n",
    "        self.rnn_layer = rnn_layer\n",
    "        self.rnn_unit = rnn_unit\n",
    "        \n",
    "        # Hidden layers\n",
    "        img_size = np.array(input_shape[2:])\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels = input_shape[1], out_channels = conv_channel[0], kernel_size = conv_kernel[0])\n",
    "        # self.bn1 = nn.BatchNorm2d(conv_channel[0])\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size = pool_kernel[0])\n",
    "        img_size = np.floor((img_size - conv_kernel[0] + 1.0) / pool_kernel[0])\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = conv_channel[0], out_channels = conv_channel[1], kernel_size = conv_kernel[1])\n",
    "        # self.bn2 = nn.BatchNorm2d(conv_channel[1])\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size = pool_kernel[1])\n",
    "        img_size = np.floor((img_size - conv_kernel[1] + 1.0) / pool_kernel[1])\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels = conv_channel[1], out_channels = conv_channel[2], kernel_size = conv_kernel[2])\n",
    "        # self.bn3 = nn.BatchNorm2d(conv_channel[2])\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size = pool_kernel[2])\n",
    "        img_size = np.floor((img_size - conv_kernel[2] + 1.0) / pool_kernel[2])\n",
    "        \n",
    "        fc_input_size = np.int(np.prod(img_size) * conv_channel[2])\n",
    "        \n",
    "        self.rnn1 = nn.LSTM(input_size = fc_input_size, hidden_size = rnn_unit[0], num_layers = rnn_layer[0], dropout = rnn_drop[0], batch_first = True)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features = rnn_unit[0] * rnn_layer[0], out_features = fc_unit[0])\n",
    "        self.drop1 = nn.Dropout(drop_out[0])\n",
    "        \n",
    "        self.fc2 = nn.Linear(in_features = fc_unit[0], out_features = out_size[0])\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        shape = x.shape\n",
    "        x = x.view(shape[0] * shape[1], shape[2], shape[3], shape[4])\n",
    "        \n",
    "        hidden = (torch.randn(self.rnn_layer[0], shape[0], self.rnn_unit[0]), \n",
    "                  torch.randn(self.rnn_layer[0], shape[0], self.rnn_unit[0]))   # for LSTM\n",
    "        # hidden = torch.randn(self.rnn_layer[0], shape[0], self.rnn_unit[0])   # for simple RNN and GRU\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)        \n",
    "        x = x.view(shape[0], shape[1], -1)\n",
    "        _, x = self.rnn1(x, hidden) # use final hidden state for non-series label prediction!\n",
    "        x = x[0].permute(1, 0, 2) # for LSTM\n",
    "        # x = x.permute(1, 0, 2) # for simple RNN and GRU\n",
    "        x = F.relu(x)\n",
    "        x = x.contiguous().view(x.shape[0], -1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function of model simulation\n",
    "def CerealTimeKillersModelSimulator(args, label,\n",
    "                                    TrainDataLoader, ValDataLoader, TestDataLoader, DataSize,\n",
    "                                    is_2D = False,\n",
    "                                    K_fold_train = False, k_folds = 1):\n",
    "    \n",
    "    N_FOLD = k_folds if K_fold_train else 1\n",
    "    loss, acc, param, models = [], [], [], []\n",
    "    \n",
    "    for fold in range(N_FOLD):\n",
    "        print('\\n%d/%d Fold' % (fold + 1, N_FOLD))\n",
    "        print('----------------------------')\n",
    "    \n",
    "        model, optimizer, criterion = CerealTimeKillersModelGenerator(args, size = DataSize)\n",
    "        loss_list, acc_list, param_norm_list, trained_model, epoch = simulation(args, label, model,\n",
    "                                                                                TrainDataLoader[fold],\n",
    "                                                                                ValDataLoader[fold],\n",
    "                                                                                TestDataLoader,\n",
    "                                                                                is_2D = is_2D,\n",
    "                                                                                optimizer = optimizer,\n",
    "                                                                                criterion = criterion)\n",
    "    \n",
    "        loss_list, acc_list = np.array(loss_list), np.array(acc_list)\n",
    "        loss.append([loss_list[0, epoch], loss_list[1, epoch], loss_list[2, epoch]])\n",
    "        acc.append([acc_list[0, epoch], acc_list[1, epoch], acc_list[2, epoch]])\n",
    "        param.append(param_norm_list[epoch])\n",
    "        models.append(trained_model)\n",
    "        \n",
    "        print('Train/Val/Test Final MSE:', list(loss[-1]))\n",
    "        print('Train/Val/Test Maximum Accuracy:', list(acc[-1]))\n",
    "    \n",
    "    return loss, acc, param, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input settings - hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CerealTimeKillersLabels:\n",
    "    \"\"\"\n",
    "    Select labels for model prediction\n",
    "    Labels used for prediction: info + electrode --> prediction\n",
    "    CHANGE these with necessity before loading data\n",
    "    \"\"\"\n",
    "    \n",
    "    # ['subject', 'game', 'gender', 'age', 'disturbance', 'experience', 'memory']\n",
    "    info = []\n",
    "        \n",
    "    # ['AF3', 'AF4', 'F3', 'F4', 'F7', 'F8', 'FC5', 'FC6', 'O1', 'O2', 'P7', 'P8', 'T7', 'T8']\n",
    "    electrode = ['AF3', 'AF4', 'F3', 'F4', 'F7', 'F8', 'FC5', 'FC6', 'O1', 'O2', 'P7', 'P8', 'T7', 'T8']\n",
    "        \n",
    "    # ['satisfied', 'boring', 'horrible', 'calm', 'funny', 'valence', 'arousal']\n",
    "    prediction = ['boring', 'horrible', 'calm', 'funny']\n",
    "    # prediction = ['valence', 'arousal']\n",
    "    \n",
    "    # Quadrant emotions (applied after predicting valence/arousal)\n",
    "    quadrant = ['boring', 'horrible', 'calm', 'funny']\n",
    "    \n",
    "    # Fixed variables\n",
    "    fixed = info + prediction\n",
    "    \n",
    "    # Summarise labels for model\n",
    "    label = info + electrode + prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: For this notebook to perform best, if possible, in the menu under `Runtime` -> `Change runtime type.`  select `GPU` \n",
      "Current device: cpu\n",
      "Random seed 2021 has been set.\n"
     ]
    }
   ],
   "source": [
    "# General settings\n",
    "workspace_dir = Fdata  + 'EMOTION-HEALTHY/'  # Workspace directionary\n",
    "\n",
    "LabelRange = [1, 10] # The [min, max] of emotional states for transformation\n",
    "\n",
    "# Whether to allow between-window dataset mixture\n",
    "# SET TO FALSE FOR 4-DIMENSIONAL INPUT WHEN USING RNN\n",
    "Is_between_subject = False # Default is True for 3-dimensional input\n",
    "\n",
    "# Whether to transform 2D emotion  (valence/arousal) to 4 quardrant emotions ()\n",
    "Is_2D_to_quardrant_emotion = False # Default is False\n",
    "\n",
    "# Which to be based for allocating testing dataset (only when Is_between_subject = True)\n",
    "Allocation_test = None # [None, 'subject', 'game'] # Default is None\n",
    "test_ratio = 0.2 # Proportion of data used for testing when Allocation_test == None\n",
    "Target_test = [25, 26, 27] # Int list for allocating corresponding game/subject as testing dataset when Allocation_test != None\n",
    "\n",
    "# Model structural settings\n",
    "N_inputtime = 50 # Time window for input sampling (Default is None for the whole timepoints)\n",
    "N_stridetime = 10 # Temporal leap for input sampling when N_inputtime != None\n",
    "N_perseg = 256 # N per seg of spectrogram\n",
    "N_framerate = 128 # Framerate of spectrogram\n",
    "\n",
    "# Model training settings\n",
    "batch_size_train = 16 # Number of examples per minibatch during training\n",
    "batch_size_test = 1 # Number of examples per minibatch during validation/testing\n",
    "k_folds = 5 # Number for K-folds for training vs validation (validation is 1/k_folds of the train/val set)\n",
    "K_fold_train = True # Whether enable the full K-fold cross-validation for training (if False, validate only once)\n",
    "\n",
    "# Model hypermparametres\n",
    "args = {\n",
    "    'epochs': 300,\n",
    "    'lr': 3e-3,\n",
    "    'momentum': 0.99,\n",
    "    'l1': 1e-3,\n",
    "    'l2': 1e-3,\n",
    "    'patience': 30,\n",
    "    'device': set_device(),\n",
    "}\n",
    "print('Current device:', args['device'])\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 2021\n",
    "set_seed(seed = SEED)\n",
    "g_seed = torch.Generator()\n",
    "g_seed.manual_seed(SEED)\n",
    "\n",
    "# Torch-based data transformation\n",
    "data_transform = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: {'train': 70, 'val': 17, 'test': 21}\n",
      "Input shape: [channel, frequency, time]\n",
      "Single input data size: (12, 14, 129, 50)\n",
      "Single output data size: (4,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Implement Dataloader\n",
    "FullDataset, DataSize, ExpIndex = CerealTimeKillersDataLoader(dir_base = workspace_dir,\n",
    "                                                              label_class = CerealTimeKillersLabels,\n",
    "                                                              label_range = LabelRange,\n",
    "                                                              dataset_mix = Is_between_subject,\n",
    "                                                              winlen = N_inputtime,\n",
    "                                                              stride = N_stridetime,\n",
    "                                                              nperseg = N_perseg,\n",
    "                                                              fs = N_framerate,\n",
    "                                                              transform = data_transform)\n",
    "\n",
    "# Implement DataSplitter\n",
    "SplittedDataset, SplittedDataLength = CerealTimeKillersDataSplitter(FullDataset, \n",
    "                                                                    exp_index = ExpIndex, \n",
    "                                                                    allocation_test = Allocation_test,\n",
    "                                                                    test_ratio = test_ratio,\n",
    "                                                                    target_test = Target_test,\n",
    "                                                                    k_folds = k_folds,\n",
    "                                                                    batch_size_train = batch_size_train,\n",
    "                                                                    batch_size_test = batch_size_test,\n",
    "                                                                    seed = SEED,\n",
    "                                                                    generator = g_seed)\n",
    "\n",
    "# Load Splited data\n",
    "(TrainDataLoader, ValDataLoader, TestDataLoader) = (SplittedDataset['train'],\n",
    "                                                    SplittedDataset['val'],\n",
    "                                                    SplittedDataset['test'])\n",
    "\n",
    "# Show data size\n",
    "print('Dataset length:', SplittedDataLength)\n",
    "print('Input shape: [channel, frequency, time]')\n",
    "print('Single input data size:', DataSize[0])\n",
    "print('Single output data size:', DataSize[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTKNet_RNN(\n",
      "  (rnn1): LSTM(90300, 128, batch_first=True)\n",
      "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (drop1): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "CTK_Net_select = CTKNet_RNN\n",
    "\n",
    "# Model selection function\n",
    "def CerealTimeKillersModelGenerator(args, size):\n",
    "    \n",
    "    model = CTK_Net_select(input_shape = size[0], out_size = size[1])\n",
    "    optimizer = optim.SGD(model.parameters(), lr = args['lr'], momentum = args['momentum'])\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    return model, optimizer, criterion\n",
    "\n",
    "\n",
    "# Model selection\n",
    "model, optimizer, criterion = CerealTimeKillersModelGenerator(args, size = DataSize)\n",
    "print(model)\n",
    "# summary(model, DataSize[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1/5 Fold\n",
      "----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c421cc2f37d4f889d1f7706a3495e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dominicburrows/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch  10 / 300\n",
      "Train/Val/TEST MSE: 0.1363688662648201 0.13375547900795937 0.13119657071573393\n",
      "Train/Val/TEST Accuracy: 39.130434782608695 16.666666666666668 38.095238095238095\n",
      "-----Epoch  20 / 300\n",
      "Train/Val/TEST MSE: 0.11725691854953765 0.10872063661615054 0.1171240389701866\n",
      "Train/Val/TEST Accuracy: 42.028985507246375 38.888888888888886 28.571428571428573\n",
      "-----Epoch  30 / 300\n",
      "Train/Val/TEST MSE: 0.1031731754541397 0.09341674235959847 0.11201404310053303\n",
      "Train/Val/TEST Accuracy: 47.82608695652174 38.888888888888886 28.571428571428573\n",
      "-----Epoch  40 / 300\n",
      "Train/Val/TEST MSE: 0.10213779658079147 0.08733093914472395 0.11211274586440552\n",
      "Train/Val/TEST Accuracy: 49.27536231884058 33.333333333333336 28.571428571428573\n",
      "-----Epoch  50 / 300\n",
      "Train/Val/TEST MSE: 0.10703501254320144 0.08596833888441324 0.11263717107829593\n",
      "Train/Val/TEST Accuracy: 39.130434782608695 33.333333333333336 28.571428571428573\n",
      "-----Epoch  60 / 300\n",
      "Train/Val/TEST MSE: 0.0989932268857956 0.08708063212947713 0.1121555616901744\n",
      "Train/Val/TEST Accuracy: 37.68115942028985 33.333333333333336 28.571428571428573\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model simulation\n",
    "loss_K, acc_K, param_K, models_K = CerealTimeKillersModelSimulator(args, CerealTimeKillersLabels, \n",
    "                                                                   TrainDataLoader,\n",
    "                                                                   ValDataLoader,\n",
    "                                                                   TestDataLoader,\n",
    "                                                                   DataSize,\n",
    "                                                                   is_2D = Is_2D_to_quardrant_emotion,\n",
    "                                                                   K_fold_train = K_fold_train,\n",
    "                                                                   k_folds = k_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val/Test Average MSE: [0.09806279629468918, 0.10167964306459124, 0.10360650115069889]\n",
      "Train/Val/Test Average Accuracy: [37.055900621118006, 30.980392156862745, 34.28571428571429]\n"
     ]
    }
   ],
   "source": [
    "# Average results from K-folds\n",
    "print('Train/Val/Test Average MSE:', list(np.mean(np.array(loss_K), axis = 0)))\n",
    "print('Train/Val/Test Average Accuracy:', list(np.mean(np.array(acc_K), axis = 0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTKNet_CRNN_1(\n",
      "  (conv1): Conv2d(14, 5, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=(1, 1), stride=(1, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=(1, 1), stride=(1, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  (rnn1): LSTM(28750, 64, batch_first=True)\n",
      "  (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "CTK_Net_select = CTKNet_CRNN_1\n",
    "\n",
    "# Model selection function\n",
    "def CerealTimeKillersModelGenerator(args, size):\n",
    "    \n",
    "    model = CTK_Net_select(input_shape = size[0], out_size = size[1])\n",
    "    optimizer = optim.SGD(model.parameters(), lr = args['lr'], momentum = args['momentum'])\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    return model, optimizer, criterion\n",
    "\n",
    "\n",
    "# Model selection\n",
    "model, optimizer, criterion = CerealTimeKillersModelGenerator(args, size = DataSize)\n",
    "print(model)\n",
    "# summary(model, DataSize[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CerealTimeKillersModelSimulator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d611dd0e1d5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Model simulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m loss_K, acc_K, param_K, models_K = CerealTimeKillersModelSimulator(args, CerealTimeKillersLabels, \n\u001b[0m\u001b[1;32m      3\u001b[0m                                                                    \u001b[0mTrainDataLoader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                                    \u001b[0mValDataLoader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                                    \u001b[0mTestDataLoader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CerealTimeKillersModelSimulator' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model simulation\n",
    "loss_K, acc_K, param_K, models_K = CerealTimeKillersModelSimulator(args, CerealTimeKillersLabels, \n",
    "                                                                   TrainDataLoader,\n",
    "                                                                   ValDataLoader,\n",
    "                                                                   TestDataLoader,\n",
    "                                                                   DataSize,\n",
    "                                                                   is_2D = Is_2D_to_quardrant_emotion,\n",
    "                                                                   K_fold_train = K_fold_train,\n",
    "                                                                   k_folds = k_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
